{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект: \"Отток клиентов\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача проекта**:\n",
    "\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "\n",
    "В рамках проекта мы проведем следующие **этапы исследования**: \n",
    "\n",
    "1) Ознакомимся с данными и подготовим их для дальнейшего исследования;\n",
    "\n",
    "2) Исследуем баланс классов, обучим модель без учета дисбаланса;\n",
    "\n",
    "3) Улучшим качество модели, учитывая дисбаланс классов. Обучим разные модели и найдем лучшую;\n",
    "\n",
    "4) Проведем финальное тестирование лучшей модели.\n",
    "\n",
    "Приступим к исследованию! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек и знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем необходимые для проекта библиотеки и алгоритмы:\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#прочтем файл: \n",
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "#выведем на экран первые 10 строк таблицы для ознакомления: \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для целей дальнейшего исследования **нам не понадобятся данные об индексе строки, уникальном идентификаторе клиента и фамилии**. Эти показатели не могу иметь какое-либо влияние на уход клиента из банка. Поэтому **удалим эти столбцы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#удалим столбцы RowNumber, CustomerId, Surname: \n",
    "df = df.drop(['RowNumber','CustomerId','Surname'], axis=1)\n",
    "#выведем на экран общую информацию о данных таблицы: \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в таблице 10000 строк, типы данных указаны верно, но **в столбце Tenure имеются пропуски - порядка 10% значений**. Посмотрим на строки с пропусками в этом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "30          591     Spain  Female   39     NaN       0.00              3   \n",
       "48          550   Germany    Male   38     NaN  103391.38              1   \n",
       "51          585   Germany    Male   36     NaN  146050.97              2   \n",
       "53          655   Germany    Male   41     NaN  125561.97              1   \n",
       "60          742   Germany    Male   35     NaN  136857.00              1   \n",
       "\n",
       "    HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "30          1               0        140469.38       1  \n",
       "48          0               1         90878.13       0  \n",
       "51          0               0         86424.57       0  \n",
       "53          0               0        164040.94       1  \n",
       "60          0               0         84509.57       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выведем на экран первые 5 строк среза таблицы, где значения столбца Tenure отсутствуют: \n",
    "df[df['Tenure'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложно предположить, почему эти данные отсутствуют, так как здесь есть пользователи с различным количеством продуктов, активные клиенты и нет, с различным доходом и т.д. В данном случае заменять пропуски на какие-либо значения мы не можем - это может повлиять на обучение модели. Придется удалить строки с пропусками. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        9091 non-null int64\n",
      "Geography          9091 non-null object\n",
      "Gender             9091 non-null object\n",
      "Age                9091 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            9091 non-null float64\n",
      "NumOfProducts      9091 non-null int64\n",
      "HasCrCard          9091 non-null int64\n",
      "IsActiveMember     9091 non-null int64\n",
      "EstimatedSalary    9091 non-null float64\n",
      "Exited             9091 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 852.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#удалим строки в пропусками: \n",
    "df = df.dropna()\n",
    "#для проверки еще раз выведем на экран общую информацию о данных таблицы: \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, данные почти готовы к исследованию. Осталось **масштабировать числовые признаки и преобразовать категориальные признаки в численные** методом прямого кодирования. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование,  кодирование признаков, разбиение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#преобразуем категориальные признаки в численные\n",
    "df = pd.get_dummies(df,drop_first=True)\n",
    "#для проверки выведем на экран 5 строк таблицы: \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как тестовой выборки у нас нет, то нам необходимо **исходные данные разбить на 3 группы**: \n",
    "\n",
    "*60% данных- обучающая выборка, 20% - валидационная, 20% - тестовая*. \n",
    "\n",
    "С помощью функции `train_test_split` мы сначала отделим 20 % для тестовой выборки,  затем от оставшихся данных отделим еще 25% для валидационной выборки, остальное- обучающая. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Размер features и target обучающей выборки:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5454, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5454,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Размер features и target валидационной и тестовой выборок:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1818, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1818,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1819, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1819,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#поделим массив данных на признаки (features_df) и целевой признак (target_df):\n",
    "features_df = df.drop('Exited', axis=1)\n",
    "target_df = df['Exited']\n",
    "#выделим 20% данных для тестовой выборки(features_test, target_test):\n",
    "features_without_test, features_test, target_without_test, target_test = train_test_split(\n",
    "    features_df, target_df, test_size=0.2, random_state=1000000, shuffle=True, stratify=target_df)\n",
    "#выделим 25% от оставшихся данных для валид-ной выборки(features_valid, target_valid),ост.- обучающая (features_train, target_train):\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_without_test, target_without_test, test_size=0.25, random_state=1000000, shuffle=True, stratify=target_without_test)\n",
    "#для проверки выведем на экран размеры получившихся выборок методом shape: \n",
    "display('Размер features и target обучающей выборки:', features_train.shape, target_train.shape)\n",
    "display('Размер features и target валидационной и тестовой выборок:', features_valid.shape, target_valid.shape, features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4539</td>\n",
       "      <td>0.700473</td>\n",
       "      <td>-0.170110</td>\n",
       "      <td>0.693273</td>\n",
       "      <td>-1.217846</td>\n",
       "      <td>0.811004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.782841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7365</td>\n",
       "      <td>-0.844792</td>\n",
       "      <td>-0.264850</td>\n",
       "      <td>1.733087</td>\n",
       "      <td>1.243123</td>\n",
       "      <td>-0.914120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.800463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4512</td>\n",
       "      <td>0.164781</td>\n",
       "      <td>1.156241</td>\n",
       "      <td>-1.039750</td>\n",
       "      <td>1.156804</td>\n",
       "      <td>-0.914120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>-0.525437</td>\n",
       "      <td>-0.833286</td>\n",
       "      <td>1.386482</td>\n",
       "      <td>0.471449</td>\n",
       "      <td>-0.914120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9396</td>\n",
       "      <td>0.515041</td>\n",
       "      <td>0.114108</td>\n",
       "      <td>-1.039750</td>\n",
       "      <td>-1.217846</td>\n",
       "      <td>0.811004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "4539     0.700473 -0.170110  0.693273 -1.217846       0.811004          1   \n",
       "7365    -0.844792 -0.264850  1.733087  1.243123      -0.914120          1   \n",
       "4512     0.164781  1.156241 -1.039750  1.156804      -0.914120          0   \n",
       "5800    -0.525437 -0.833286  1.386482  0.471449      -0.914120          1   \n",
       "9396     0.515041  0.114108 -1.039750 -1.217846       0.811004          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "4539               1        -0.782841                  0                0   \n",
       "7365               1        -0.800463                  0                1   \n",
       "4512               0         0.983212                  0                0   \n",
       "5800               1         0.361967                  0                0   \n",
       "9396               0         1.725335                  0                1   \n",
       "\n",
       "      Gender_Male  \n",
       "4539            0  \n",
       "7365            0  \n",
       "4512            1  \n",
       "5800            1  \n",
       "9396            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проведем масштабирование числовых признаков: \n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "#дополнительно проведем масштабирование числовых признаков для выборки features_without_test- она понадобится нам при тестировании: \n",
    "scaler.fit(features_without_test[numeric])\n",
    "features_without_test[numeric] = scaler.transform(features_without_test[numeric])\n",
    "#для проверки выведем на экран 5 строк таблицы features_test: \n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши данные готовы к исследованию!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для расчета AUC-ROC и F1-меры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе проекта нам не раз придется прибегнуть к расчету метрик качества- AUC-ROC и F1-меры. Для удобства заранее запишем функцию, которая на вход принимает параметры модели, обучающую и валидационную выборки, а на выходе дает метрики AUC-ROC и F1-мера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция, которая на вход принимает параметры модели, на выходе дает метрики качества (AUC-ROC и F1-мера):\n",
    "def quality_metrics (model, features_train, target_train,features_valid, target_valid):\n",
    "    model.fit(features_train,target_train)\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)#F-1-мера\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)#AUC-ROC\n",
    "    return f1, auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод** \n",
    "\n",
    "На этапе подготовки данных мы импортировали необходимые для дальнейшей работы библиотеки и алгоритмы, ознакомились с общей информацией о данных в таблице, провели предобработку данных и получили 3 выборки: обучающая (features_train, target_train), тестовая (features_test, target_test) и валидационная (features_valid, target_valid), выделенные из исходного датасета в соотношении 3/1/1. \n",
    "\n",
    "Приступим к исследованию! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование баланса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим, как распределены ответы нашего целевого признака. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.796062\n",
       "1    0.203938\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#с помощью метода value_counts выведем на экран относительные частоты встречаемых ответов 0 и 1:\n",
    "target_df.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные несбалансированы. Значения \"0\" в 4 раза превышают \"1\". Посмотрим, какое влияние окажет несбалансированность классов на обучение моделей. \n",
    "\n",
    "Обучим 3 модели: модель решающего дерева, модель случайного леса и модель логистической регрессии с рандомными параметрами и без учета дисбаланса, проверим метрики качества: AUC-ROC и F1-мера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение моделей без учета дисбаланса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**РЕШАЮЩЕЕ ДЕРЕВО**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5056039850560399"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6944556727647313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#посчитаем метрики качества (AUC-ROC и F1-мера) для модели решающего дерева:\n",
    "model_1 = DecisionTreeClassifier(random_state=1000000)\n",
    "f1_1, auc_roc_1 = quality_metrics(model_1, features_train, target_train,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_1)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**СЛУЧАЙНЫЙ ЛЕС**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5601317957166392"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8174389991747961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#посчитаем метрики качества (AUC-ROC и F1-мера) для модели случайного леса:\n",
    "model_2 = RandomForestClassifier(random_state=1000000)\n",
    "f1_2, auc_roc_2 = quality_metrics(model_2, features_train, target_train,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_2)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3137254901960785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7520047984770051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#посчитаем метрики качества (AUC-ROC и F1-мера) для модели логистической регрессии:\n",
    "model_3 = LogisticRegression(random_state=1000000, solver='liblinear')\n",
    "f1_3, auc_roc_3 = quality_metrics(model_3, features_train, target_train,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_3)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Представим результаты исследования качества моделей в виде таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>модель</th>\n",
       "      <th>F-1-мера</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Решающее дерево</td>\n",
       "      <td>0.505604</td>\n",
       "      <td>0.694456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.560132</td>\n",
       "      <td>0.817439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.752005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    модель  F-1-мера   AUC-ROC\n",
       "0          Решающее дерево  0.505604  0.694456\n",
       "1            Случайный лес  0.560132  0.817439\n",
       "2  Логистическая регрессия  0.313725  0.752005"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'модель' : ['Решающее дерево', 'Случайный лес', 'Логистическая регрессия'],\n",
    "                       'F-1-мера' : [f1_1, f1_2, f1_3],\n",
    "                       'AUC-ROC' : [auc_roc_1, auc_roc_2, auc_roc_3]})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках исследования задачи был выявлен дисбаланс классов: значения \"0\" в 4 раза превышают \"1\".  Чтобы проверить, какое влияние окажет несбалансированность классов на обучение моделей, мы обучили 3 модели без учета дисбаланса. Результаты работы моделей модем наблюдать в таблице выше. \n",
    "\n",
    "При проверке качества моделей критерием AUC-ROC мы выявили значения выше 0,5, но важно помнить, что этот критерий по сравнению с F-1-мерой более устойчив к несбалансированным классам, а вот значения критерия F-1-меры далеки от идеала. В рамках проекта нам необходимо довести метрику F-1-мера до 0.59, на несбалансированных данных такого результата мы не получили. \n",
    "\n",
    "Улучшим качество модели, учитывая дисбаланс классов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аргумент class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь, для борьбы с дисбалансом классов воспользуемся `аргументом class_weight` алгоритмов моделей решающего дерева, случайного леса и логистической регрессии. \n",
    "\n",
    "А также для улучшения качества моделей с помощью модуля GridSearchCV подберем оптимальные гиперпараметры. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**РЕШАЮЩЕЕ ДЕРЕВО**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#с помощью модуля GridSearchCV подберем оптимальные гиперпараметры для модели решающего дерева (model_4):\n",
    "model_4 = DecisionTreeClassifier(random_state=1000000, class_weight='balanced')\n",
    "parametrs_4 = { 'max_depth': range (1,10),\n",
    "              'min_samples_leaf': range (1,8),\n",
    "              'min_samples_split': range (2,10,2) }\n",
    "grid_4 = GridSearchCV(model_4, parametrs_4, cv=5, scoring='f1')\n",
    "grid_4.fit(features_train,target_train)\n",
    "display(grid_4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.542110358180058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8252244163498417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#перезапишем модель(model_4) с оптимальными гиперпараметрами и найдем показатели качества AUC-ROC и F1-мера:\n",
    "model_4 = DecisionTreeClassifier(random_state=1000000, max_depth=5, min_samples_leaf=3, min_samples_split=8, class_weight='balanced')\n",
    "f1_4, auc_roc_4 = quality_metrics(model_4, features_train, target_train,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_4)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**СЛУЧАЙНЫЙ ЛЕС**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 30}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#с помощью модуля GridSearchCV подберем оптимальные гиперпараметры для модели случайного леса (model_5):\n",
    "model_5 = RandomForestClassifier(random_state=1000000, class_weight='balanced')\n",
    "parametrs_5 = {'n_estimators': range (10, 51, 10),\n",
    "              'max_depth': range (1,11)}\n",
    "grid_5 = GridSearchCV(model_5, parametrs_5, cv=5, scoring='f1')\n",
    "grid_5.fit(features_train,target_train)\n",
    "display(grid_5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.592964824120603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8487026788392008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#перезапишем модель(model_5) с оптимальными гиперпараметрами и найдем показатели качества AUC-ROC и F1-мера:\n",
    "model_5 = RandomForestClassifier(random_state=1000000, n_estimators=30, max_depth=9, class_weight='balanced')\n",
    "f1_5, auc_roc_5 = quality_metrics(model_5, features_train, target_train,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_5)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.47970479704797053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7582878974437306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#обучим модель лог.регрессии(model_6) с учетом аргумента class_weight='balanced' и найдем показатели качества AUC-ROC и F1-мера:\n",
    "model_6 = LogisticRegression(random_state=1000000, solver='liblinear', class_weight='balanced')\n",
    "f1_6, auc_roc_6 = quality_metrics(model_6, features_train, target_train,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_6)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Представим результаты исследования качества моделей \n",
    "с учетом дисбаланса классов (с помощью аргумента class_weight) в виде таблицы**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>модель</th>\n",
       "      <th>F-1-мера</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Решающее дерево</td>\n",
       "      <td>0.542110</td>\n",
       "      <td>0.825224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.848703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.479705</td>\n",
       "      <td>0.758288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    модель  F-1-мера   AUC-ROC\n",
       "0          Решающее дерево  0.542110  0.825224\n",
       "1            Случайный лес  0.592965  0.848703\n",
       "2  Логистическая регрессия  0.479705  0.758288"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'модель' : ['Решающее дерево', 'Случайный лес', 'Логистическая регрессия'],\n",
    "                       'F-1-мера' : [f1_4, f1_5, f1_6],\n",
    "                       'AUC-ROC' : [auc_roc_4, auc_roc_5, auc_roc_6]})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря учету баланса классов, а также подбору оптимальных гиперпараметров, улучшились метрики качества по всем моделям, а метрика F-1-мера модели случайного леса достигла необходимого уровня - 0,59. Пока можем считать эту модель лучшей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки техникой downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для борьбы с дисбалансом классов попробуем еще один метод - технику downsampling. \n",
    "\n",
    "Создадим функцию, которая на выходе даст обучающую выборку, уменьшенную по технике downsampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запишем функцию\n",
    "def downsampling (features, target, fraction):\n",
    "    features_zeros = features[target==0]\n",
    "    features_ones = features[target==1]\n",
    "    target_zeros = target[target==0]\n",
    "    target_ones = target[target==1]\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=1000000)]+[features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=1000000)]+[target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=1000000)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Размер features_downsampled и target_downsampled :'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2415, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2415,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#получим новую обучающую выборку: \n",
    "features_downsampled, target_downsampled = downsampling (features_train, target_train, 0.3)\n",
    "#для проверки выведем на экран размеры получившихся выборок методом shape: \n",
    "display('Размер features_downsampled и target_downsampled :', features_downsampled.shape, target_downsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Найдем показатели качества AUC-ROC и F1-мера только для модели случайного леса, так как ранее именно эта модель показала наилучший результат по метрике F-1-мера.**\n",
    "\n",
    "Так как проводить кросс-валидацию на upsampled/downsampled данных – некорректно, так как баланс классов нарушен и  внутри кросс-валидации происходит разбиение переданной в нее выборки на треин и валидацию, **подберем параметры вручную**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**СЛУЧАЙНЫЙ ЛЕС**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Оптимальные ГП для модели model_7 с наибольшим f1='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5910112359550562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "': n_estimators='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "', max_depth='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#подберем оптимальные гиперпараметры для модели случайного леса (model_7) с учетом новой обучающей выборки:\n",
    "best_model =  None\n",
    "best_f1 = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range (10,41,10):\n",
    "    for depth in range (1,10):\n",
    "        model = RandomForestClassifier(random_state=1000000,n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "        predict_valid = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predict_valid)\n",
    "        if f1 > best_f1:\n",
    "            best_model =  model\n",
    "            best_f1 = f1\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "display('Оптимальные ГП для модели model_7 с наибольшим f1=',best_f1,': n_estimators=', best_est, ', max_depth=', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5910112359550562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на валидационной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8434329228425016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#найдем показатели качества AUC-ROC и F1-мера для случайного леса на новых обучающих данных:\n",
    "model_7 = RandomForestClassifier(random_state=1000000, n_estimators=20, max_depth=8)\n",
    "f1_7, auc_roc_7 = quality_metrics(model_7, features_downsampled, target_downsampled,features_valid, target_valid)\n",
    "display('F-1-мера модели решающего дерева на валидационной выборке:', f1_7)\n",
    "display('AUC-ROC модели решающего дерева на валидационной выборке:', auc_roc_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получены довольно высокие значения F1-меры и AUC-ROC, однако ниже, чем у модели случайного леса, обученной на сбалансированных данных с помощью аргумента class_weight.\n",
    "\n",
    "Таким образом, модель, показавшая наилучший результат в рамках исследования - это model_5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "С целью улучшения качества моделей мы избавлялись от дисбаланса классов 2 методами: с помощью аргумента class_weight алгоритмов моделей, а также путем уменьшения обучающей выборки техникой downsampling. \n",
    "\n",
    "Наилучшие показатели качества выдала модель случайного леса, обученная на сбалансированных данных с помощью аргумента class_weight = 'balanced', с гиперпараметрами 'max_depth'= 9, 'n_estimators'= 30. Эта модель выдала следующие значения метрик качества на валидационных данных:  F-1-мера = 0.5929, AUC-ROC = 0.8486. Эту модель можем считать успешной, поскольку показатель F-1-меры=0.59, что удовлетворяет задаче нашего проекта. \n",
    "\n",
    "Протестируем эту модель на тестовой выборке. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим нашу лучшую модель случайного леса `model_5` на тестовой выборке, найдем показатели качества AUC-ROC и F1-мера. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на  тестовой выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6375321336760926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на тестовой выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8636282408303673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#найдем показатели качества AUC-ROC и F1-мера на тестовой выборке: \n",
    "f1_test, auc_roc_test = quality_metrics(model_5, features_train, target_train,features_test, target_test)\n",
    "display('F-1-мера модели решающего дерева на  тестовой выборке:', f1_test)\n",
    "display('AUC-ROC модели решающего дерева на тестовой выборке:', auc_roc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке наша модель показала еще более высокие показатели качества: F-1-мера = 0.6375, AUC-ROC = 0.8636. \n",
    "Проверим, как изменятся эти показатели, если мы **проведем обучение модели на объединенных данных обучающей и валидационной выборок, а затем посчитаем метрики качества на тестовой выборке**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 20}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#с помощью модуля GridSearchCV подберем оптимальные гиперпараметры для модели случайного леса (model_8), обученной на объединенных данных:\n",
    "model_8 = RandomForestClassifier(random_state=1000000, class_weight='balanced')\n",
    "parametrs_8 = {'n_estimators': range (10, 51, 10),\n",
    "              'max_depth': range (1,11)}\n",
    "grid_8 = GridSearchCV(model_8, parametrs_8, cv=5, scoring='f1')\n",
    "grid_8.fit(features_without_test, target_without_test)\n",
    "display(grid_8.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на тестовой выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6191051995163241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AUC-ROC модели решающего дерева на тестовой выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8636933925034623"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#перезапишем модель(model_8) с оптимальными гиперпараметрами и найдем показатели качества AUC-ROC и F1-мера на тестовой выборке:\n",
    "model_8 = RandomForestClassifier(random_state=1000000, n_estimators=20, max_depth=9, class_weight='balanced')\n",
    "f1_8, auc_roc_8 = quality_metrics(model_8, features_without_test, target_without_test,features_test, target_test)\n",
    "display('F-1-мера модели решающего дерева на тестовой выборке:', f1_8)\n",
    "display('AUC-ROC модели решающего дерева на тестовой выборке:', auc_roc_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После переобучения модели на объединенных данных качество осталось практически на том же уровне."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки модели на адекватность **проверим эффективность предсказаний модели, которая предсказывает рандомно 0 или 1**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-1-мера модели решающего дерева на фиктивных предсказаниях:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2992874109263658"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#создадим список с рандомными предсказаниями 0 и 1 (random_predictions):\n",
    "random_predictions = []\n",
    "for _ in range(len(target_test)):\n",
    "    random_predictions.append(randint(0,1))\n",
    "#найдем значение F1-меры на фиктивных предсказаниях: \n",
    "f1_fict = f1_score(target_test, random_predictions)\n",
    "#выведем на экран: \n",
    "display('F-1-мера модели решающего дерева на фиктивных предсказаниях:', f1_fict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение F-1-меры, равное 0.29, гораздо ниже значений любой исследованной в данном проекте модели. Таким образом, наша модель проверку на адекватность прошла. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "В рамках тестирования модели мы проверили работу нашей лучшей модели на тестовой выборке. На тестовой выборке модель показала еще более высокие показатели качества, чем на валидационной: F-1-мера = 0.6392, AUC-ROC = 0.8635. \n",
    "\n",
    "Затем мы попробовали еще улучшить эти показатели, проведя обучение модели на объединенных данных обучающей и валидационной выборок, однако после переобучения модели на объединенных данных качество осталось практически на том же уровне.\n",
    "\n",
    "И наконец, для проверки модели на адекватность мы сравнили результат метрики F-1-мера нашей модели с моделью, которая предсказывает рандомно 0 или 1. У фиктивной модели значение F-1-меры равно 0.29, что гораздо ниже значений любой исследованной в данном проекте модели. Таким образом, наша модель проверку на адекватность прошла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подведения итогов исследования давайте еще раз вспомним *задачу, которая стояла перед нами в начале исследования*: \n",
    "\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59.\n",
    "\n",
    "*В рамках исследования* был выявлен дисбаланс классов: значения \"0\" в 4 раза превышают \"1\". Это и понятно, ситуация, когда из банка уходит половина клиентов была бы критичной. \n",
    "\n",
    "С целью улучшения качества моделей мы избавлялись от дисбаланса классов 2 методами: с помощью аргумента class_weight алгоритмов моделей, а также путем уменьшения обучающей выборки техникой downsampling.\n",
    "\n",
    "Наилучшие показатели качества выдала модель случайного леса, обученная на сбалансированных данных с помощью аргумента class_weight = 'balanced', с гиперпараметрами 'max_depth'= 9, 'n_estimators'= 30. Эта модель выдала следующие значения метрик качества на валидационных данных: F-1-мера = 0.5929, AUC-ROC = 0.8487. Эту модель можем считать успешной, поскольку показатель F-1-меры=0.59, что удовлетворяет задаче нашего проекта.\n",
    "\n",
    "На тестовой выборке модель показала еще более высокие показатели качества, чем на валидационной: F-1-мера = 0.6375, AUC-ROC = 0.8636.\n",
    "\n",
    "Таким образом, *обученная модель удовлетворяет требованию заказчика (довести метрику до 0.59) и может быть использована в дальнейшем для предсказания ухода клиентов из банка и принятия мер по сохранению этих клиентов*. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 997,
    "start_time": "2022-02-17T20:05:21.973Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-17T20:05:35.662Z"
   },
   {
    "duration": 61,
    "start_time": "2022-02-17T20:07:04.343Z"
   },
   {
    "duration": 349,
    "start_time": "2022-02-17T20:15:58.327Z"
   },
   {
    "duration": 274,
    "start_time": "2022-02-17T20:16:36.074Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-17T20:17:40.652Z"
   },
   {
    "duration": 280,
    "start_time": "2022-02-17T20:17:59.870Z"
   },
   {
    "duration": 260,
    "start_time": "2022-02-17T20:18:22.351Z"
   },
   {
    "duration": 275,
    "start_time": "2022-02-17T20:18:40.517Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-17T20:18:58.692Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-17T20:19:00.856Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-17T20:19:15.919Z"
   },
   {
    "duration": 295,
    "start_time": "2022-02-17T20:19:45.615Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-17T20:19:50.585Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-17T20:19:51.102Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-17T20:19:54.392Z"
   },
   {
    "duration": 2258,
    "start_time": "2022-02-17T20:23:54.720Z"
   },
   {
    "duration": 265,
    "start_time": "2022-02-17T20:23:57.005Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-17T20:24:03.473Z"
   },
   {
    "duration": 36,
    "start_time": "2022-02-17T20:24:04.220Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-17T20:24:06.144Z"
   },
   {
    "duration": 6357,
    "start_time": "2022-02-17T20:24:07.263Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-17T20:24:17.856Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-17T20:28:05.905Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-17T20:29:52.356Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-17T20:37:35.861Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-17T20:38:41.663Z"
   },
   {
    "duration": 24,
    "start_time": "2022-02-17T20:54:42.637Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-17T20:56:57.465Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-17T20:57:56.913Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-17T20:58:18.446Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-17T21:05:47.821Z"
   },
   {
    "duration": 3153,
    "start_time": "2022-02-18T08:36:00.748Z"
   },
   {
    "duration": 1240,
    "start_time": "2022-02-18T08:36:13.004Z"
   },
   {
    "duration": 57,
    "start_time": "2022-02-18T08:36:14.246Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T08:36:14.306Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-18T08:36:14.318Z"
   },
   {
    "duration": 36,
    "start_time": "2022-02-18T08:36:14.333Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-18T08:36:14.372Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-18T08:36:14.402Z"
   },
   {
    "duration": 58,
    "start_time": "2022-02-18T08:36:14.433Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-18T08:36:14.493Z"
   },
   {
    "duration": 291,
    "start_time": "2022-02-18T08:57:13.681Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-18T08:57:24.080Z"
   },
   {
    "duration": 92,
    "start_time": "2022-02-18T09:01:27.093Z"
   },
   {
    "duration": 50,
    "start_time": "2022-02-18T09:05:35.923Z"
   },
   {
    "duration": 346,
    "start_time": "2022-02-18T15:46:09.377Z"
   },
   {
    "duration": 1118,
    "start_time": "2022-02-18T15:46:20.861Z"
   },
   {
    "duration": 43,
    "start_time": "2022-02-18T15:46:21.981Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-18T15:46:22.026Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-18T15:46:22.063Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T15:46:22.076Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-18T15:46:22.087Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-18T15:46:22.109Z"
   },
   {
    "duration": 39,
    "start_time": "2022-02-18T15:46:22.128Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-18T15:46:22.170Z"
   },
   {
    "duration": 36,
    "start_time": "2022-02-18T15:46:22.177Z"
   },
   {
    "duration": 102,
    "start_time": "2022-02-18T15:46:22.214Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-18T15:46:22.318Z"
   },
   {
    "duration": 191,
    "start_time": "2022-02-18T15:46:22.356Z"
   },
   {
    "duration": 15412,
    "start_time": "2022-02-18T16:11:47.405Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-18T16:14:43.086Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T16:15:15.468Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T16:15:21.035Z"
   },
   {
    "duration": 428,
    "start_time": "2022-02-18T16:22:08.700Z"
   },
   {
    "duration": 23035,
    "start_time": "2022-02-18T16:22:19.700Z"
   },
   {
    "duration": 150,
    "start_time": "2022-02-18T16:24:27.633Z"
   },
   {
    "duration": 71,
    "start_time": "2022-02-18T16:31:04.678Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T16:31:40.770Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-18T16:34:13.352Z"
   },
   {
    "duration": 42,
    "start_time": "2022-02-18T16:34:13.359Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T16:34:13.404Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T16:34:13.414Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-18T16:34:13.426Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-18T16:34:13.452Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-18T16:34:13.477Z"
   },
   {
    "duration": 51,
    "start_time": "2022-02-18T16:34:13.499Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-18T16:34:13.552Z"
   },
   {
    "duration": 48,
    "start_time": "2022-02-18T16:34:13.560Z"
   },
   {
    "duration": 91,
    "start_time": "2022-02-18T16:34:13.609Z"
   },
   {
    "duration": 50,
    "start_time": "2022-02-18T16:34:13.701Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T16:34:13.753Z"
   },
   {
    "duration": 15013,
    "start_time": "2022-02-18T16:34:13.847Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-18T16:34:28.862Z"
   },
   {
    "duration": 23017,
    "start_time": "2022-02-18T16:34:28.889Z"
   },
   {
    "duration": 158,
    "start_time": "2022-02-18T16:34:51.907Z"
   },
   {
    "duration": 86,
    "start_time": "2022-02-18T16:34:52.067Z"
   },
   {
    "duration": 93,
    "start_time": "2022-02-18T16:34:52.155Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T16:45:27.411Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T16:46:43.902Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T16:47:22.755Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-18T16:51:57.954Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-18T16:53:34.542Z"
   },
   {
    "duration": 74,
    "start_time": "2022-02-18T16:55:21.530Z"
   },
   {
    "duration": 53,
    "start_time": "2022-02-18T16:57:39.894Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T16:57:50.127Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-18T16:59:40.800Z"
   },
   {
    "duration": 44,
    "start_time": "2022-02-18T16:59:40.805Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T16:59:40.850Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T16:59:40.860Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T16:59:40.872Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-18T16:59:40.883Z"
   },
   {
    "duration": 51,
    "start_time": "2022-02-18T16:59:40.908Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-18T16:59:40.961Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T16:59:40.985Z"
   },
   {
    "duration": 72,
    "start_time": "2022-02-18T16:59:40.991Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-18T16:59:41.064Z"
   },
   {
    "duration": 71,
    "start_time": "2022-02-18T16:59:41.099Z"
   },
   {
    "duration": 84,
    "start_time": "2022-02-18T16:59:41.171Z"
   },
   {
    "duration": 95,
    "start_time": "2022-02-18T16:59:41.256Z"
   },
   {
    "duration": 14926,
    "start_time": "2022-02-18T16:59:41.352Z"
   },
   {
    "duration": 24,
    "start_time": "2022-02-18T16:59:56.279Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-18T17:01:05.954Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-18T17:01:17.572Z"
   },
   {
    "duration": 38,
    "start_time": "2022-02-18T17:01:17.577Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T17:01:17.617Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-18T17:01:17.626Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-18T17:01:17.640Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-18T17:01:17.652Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-18T17:01:17.675Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-18T17:01:17.695Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-18T17:01:17.718Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T17:01:17.764Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-18T17:01:17.775Z"
   },
   {
    "duration": 72,
    "start_time": "2022-02-18T17:01:17.810Z"
   },
   {
    "duration": 70,
    "start_time": "2022-02-18T17:01:17.884Z"
   },
   {
    "duration": 95,
    "start_time": "2022-02-18T17:01:17.956Z"
   },
   {
    "duration": 14696,
    "start_time": "2022-02-18T17:01:18.053Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-18T17:01:32.751Z"
   },
   {
    "duration": 23012,
    "start_time": "2022-02-18T17:03:18.472Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-18T17:03:56.710Z"
   },
   {
    "duration": 170,
    "start_time": "2022-02-18T17:04:14.549Z"
   },
   {
    "duration": 184,
    "start_time": "2022-02-18T17:05:26.363Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-18T17:06:13.068Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T17:32:23.912Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T17:35:18.298Z"
   },
   {
    "duration": 720,
    "start_time": "2022-02-18T17:44:04.289Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T17:44:54.363Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-18T17:45:00.460Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-18T17:46:34.243Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-18T17:51:27.940Z"
   },
   {
    "duration": 103,
    "start_time": "2022-02-18T17:53:22.870Z"
   },
   {
    "duration": 142,
    "start_time": "2022-02-18T17:53:49.032Z"
   },
   {
    "duration": 354,
    "start_time": "2022-02-18T17:53:56.894Z"
   },
   {
    "duration": 101,
    "start_time": "2022-02-18T17:54:06.650Z"
   },
   {
    "duration": 55675,
    "start_time": "2022-02-18T17:59:16.078Z"
   },
   {
    "duration": 77,
    "start_time": "2022-02-18T18:01:10.186Z"
   },
   {
    "duration": 326,
    "start_time": "2022-02-18T18:03:26.640Z"
   },
   {
    "duration": 55578,
    "start_time": "2022-02-18T18:03:35.391Z"
   },
   {
    "duration": 78,
    "start_time": "2022-02-18T18:04:49.142Z"
   },
   {
    "duration": 166,
    "start_time": "2022-02-18T18:23:41.763Z"
   },
   {
    "duration": 210,
    "start_time": "2022-02-18T18:29:52.407Z"
   },
   {
    "duration": 230,
    "start_time": "2022-02-18T18:30:02.263Z"
   },
   {
    "duration": 106,
    "start_time": "2022-02-18T18:30:24.345Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-18T18:39:13.972Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-18T18:39:13.979Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T18:39:14.022Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-18T18:39:14.034Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-18T18:39:14.050Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-18T18:39:14.067Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-18T18:39:14.098Z"
   },
   {
    "duration": 47,
    "start_time": "2022-02-18T18:39:14.119Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T18:39:14.180Z"
   },
   {
    "duration": 79,
    "start_time": "2022-02-18T18:39:14.186Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-18T18:39:14.267Z"
   },
   {
    "duration": 84,
    "start_time": "2022-02-18T18:39:14.303Z"
   },
   {
    "duration": 177,
    "start_time": "2022-02-18T18:39:14.388Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-18T18:39:14.649Z"
   },
   {
    "duration": 15610,
    "start_time": "2022-02-18T18:39:14.664Z"
   },
   {
    "duration": 24,
    "start_time": "2022-02-18T18:39:30.275Z"
   },
   {
    "duration": 24402,
    "start_time": "2022-02-18T18:39:30.301Z"
   },
   {
    "duration": 300,
    "start_time": "2022-02-18T18:39:54.704Z"
   },
   {
    "duration": 156,
    "start_time": "2022-02-18T18:39:55.005Z"
   },
   {
    "duration": 85,
    "start_time": "2022-02-18T18:39:55.163Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-18T18:39:55.250Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-18T18:39:55.259Z"
   },
   {
    "duration": 62335,
    "start_time": "2022-02-18T18:39:55.285Z"
   },
   {
    "duration": 88,
    "start_time": "2022-02-18T18:40:57.622Z"
   },
   {
    "duration": 195,
    "start_time": "2022-02-18T18:40:57.711Z"
   },
   {
    "duration": 30106,
    "start_time": "2022-02-18T18:40:57.908Z"
   },
   {
    "duration": 199,
    "start_time": "2022-02-18T18:41:28.016Z"
   },
   {
    "duration": 196,
    "start_time": "2022-02-18T18:44:16.056Z"
   },
   {
    "duration": 311,
    "start_time": "2022-02-18T18:45:03.764Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T18:49:51.233Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-18T18:50:35.883Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-18T18:55:22.736Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-18T18:55:57.508Z"
   },
   {
    "duration": 154,
    "start_time": "2022-02-18T18:57:45.812Z"
   },
   {
    "duration": 113,
    "start_time": "2022-02-18T18:58:02.986Z"
   },
   {
    "duration": 146,
    "start_time": "2022-02-18T18:58:15.678Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-18T18:58:25.688Z"
   },
   {
    "duration": 401,
    "start_time": "2022-02-18T19:00:50.172Z"
   },
   {
    "duration": 348,
    "start_time": "2022-02-18T19:01:40.748Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-18T19:02:15.571Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-18T19:04:20.086Z"
   },
   {
    "duration": 289,
    "start_time": "2022-02-22T13:02:43.099Z"
   },
   {
    "duration": 281,
    "start_time": "2022-02-22T13:04:08.288Z"
   },
   {
    "duration": 427,
    "start_time": "2022-02-22T13:09:34.842Z"
   },
   {
    "duration": 326,
    "start_time": "2022-02-22T13:12:05.704Z"
   },
   {
    "duration": 81,
    "start_time": "2022-02-22T13:13:38.144Z"
   },
   {
    "duration": 264,
    "start_time": "2022-02-22T14:10:56.043Z"
   },
   {
    "duration": 1039,
    "start_time": "2022-02-22T14:11:30.253Z"
   },
   {
    "duration": 43,
    "start_time": "2022-02-22T14:11:31.294Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-22T14:11:31.339Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-22T14:11:31.349Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-22T14:11:31.362Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-22T14:11:31.373Z"
   },
   {
    "duration": 54,
    "start_time": "2022-02-22T14:11:31.395Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-22T14:11:31.452Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-22T14:11:31.495Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-22T14:11:31.532Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-22T14:11:31.542Z"
   },
   {
    "duration": 98,
    "start_time": "2022-02-22T14:11:31.580Z"
   },
   {
    "duration": 62,
    "start_time": "2022-02-22T14:11:31.679Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-22T14:11:31.832Z"
   },
   {
    "duration": 15655,
    "start_time": "2022-02-22T14:11:31.845Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-22T14:11:47.502Z"
   },
   {
    "duration": 22586,
    "start_time": "2022-02-22T14:11:47.535Z"
   },
   {
    "duration": 194,
    "start_time": "2022-02-22T14:12:10.122Z"
   },
   {
    "duration": 121,
    "start_time": "2022-02-22T14:12:10.317Z"
   },
   {
    "duration": 98,
    "start_time": "2022-02-22T14:12:10.440Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-22T14:12:10.540Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-22T14:12:10.546Z"
   },
   {
    "duration": 3275,
    "start_time": "2022-02-22T14:12:10.563Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-22T14:12:13.840Z"
   },
   {
    "duration": 178,
    "start_time": "2022-02-22T14:12:13.859Z"
   },
   {
    "duration": 27126,
    "start_time": "2022-02-22T14:12:14.039Z"
   },
   {
    "duration": 269,
    "start_time": "2022-02-22T14:12:41.166Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-22T14:12:41.437Z"
   },
   {
    "duration": 166,
    "start_time": "2022-02-22T14:13:04.228Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-22T14:16:05.751Z"
   },
   {
    "duration": 1945,
    "start_time": "2022-02-22T14:23:00.945Z"
   },
   {
    "duration": 68,
    "start_time": "2022-02-22T14:23:22.081Z"
   },
   {
    "duration": 1891,
    "start_time": "2022-02-22T14:24:08.026Z"
   },
   {
    "duration": 125,
    "start_time": "2022-02-22T14:25:54.666Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
